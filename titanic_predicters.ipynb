{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# %load myfirstforest\n",
    "\"\"\" Writing my first randomforest code.\n",
    "Author : AstroDave\n",
    "Date : 23rd September 2012\n",
    "Revised: 15 April 2014\n",
    "please see packages.python.org/milk/randomforests.html for more\n",
    "\n",
    "\"\"\" \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "\n",
    "# Data cleanup\n",
    "# TRAIN DATA\n",
    "train_df = pd.read_csv('train.csv', header=0)        # Load the train file into a dataframe\n",
    "\n",
    "# I need to convert all strings to integer classifiers.\n",
    "# I need to fill in the missing values of the data and make it complete.\n",
    "\n",
    "# female = 0, Male = 1\n",
    "train_df['Gender'] = train_df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "# Embarked from 'C', 'Q', 'S'\n",
    "# Note this is not ideal: in translating categories to numbers, Port \"2\" is not 2 times greater than Port \"1\", etc.\n",
    "\n",
    "# All missing Embarked -> just make them embark from most common place\n",
    "if len(train_df.Embarked[ train_df.Embarked.isnull() ]) > 0:\n",
    "    train_df.Embarked[ train_df.Embarked.isnull() ] = train_df.Embarked.dropna().mode().values\n",
    "#dataframe.isnull() zwraca rzędy(elementy) wszystkich które mają nulla,\n",
    "#dataframe.dropna() zwraca dataframe'a tylko że bez rzędów które mają NaN\n",
    "#dataframe.mode() zwraca najczęstsze wartosci\n",
    "#czyli powyższa linijka wszystkie nulle zamienia w najczestrza wartość\n",
    "\n",
    "\n",
    "Ports = list(enumerate(np.unique(train_df['Embarked'])))    # determine all values of Embarked,\n",
    "#train_df['Embarked']=train_df.Embarked\n",
    "#print(list(enumerate(np.unique(train_df.Embarked)))) = [(0, 'C'), (1, 'Q'), (2, 'S')]\n",
    "Ports_dict = { name : i for i, name in Ports }              # set up a dictionary in the form  Ports : index\n",
    "train_df.Embarked = train_df.Embarked.map( lambda x: Ports_dict[x]).astype(int)     # Convert all Embark strings to int\n",
    "# print(train_df.Embarked) teraz embarked zmienilismy na wartosci int 0,1,2\n",
    "\n",
    "\n",
    "# All the ages with no data -> make the median of all Ages\n",
    "median_age = train_df['Age'].dropna().median()\n",
    "if len(train_df.Age[ train_df.Age.isnull() ]) > 0:\n",
    "    train_df.loc[ (train_df.Age.isnull()), 'Age'] = median_age\n",
    "\n",
    "# Remove the Name column, Cabin, Ticket, and Sex (since I copied and filled it to Gender)\n",
    "train_df = train_df.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'PassengerId'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#używane dane train data i test data\n",
    "\n",
    "train_data = train_df.values[:400]\n",
    "test_data = train_df.values[400:,1:]\n",
    "goodout=train_df.values[400:,0].astype(int)\n",
    "from random import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rState =  4066384865\n",
      "Random Forest:\n",
      "n_estimators=10:\n",
      "Accuracy =  81.466395112 %\n",
      "n_estimators=50:\n",
      "Accuracy =  81.466395112 %\n",
      "n_estimators=100:\n",
      "Accuracy =  80.4480651731 %\n",
      "n_estimators=200:\n",
      "Accuracy =  80.6517311609 %\n",
      "max_depth=7, instead 5:\n",
      "Accuracy =  81.0590631365 %\n",
      "max_depth=9\n",
      "Accuracy =  81.8737270876 %\n",
      "n_est=200,m_dep=7,bootstrap=False\n",
      "Accuracy =  81.466395112 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rState=int(rand()*4294967295)\n",
    "print 'rState = ',rState\n",
    "#jakis Random Forest:\n",
    "print 'Random Forest:'\n",
    "#zwiekszanie max_depth zwieksza accuracy ale dla 100 jest slabo w okolicach 5 jest dobrze\n",
    "print 'n_estimators=10:'\n",
    "forest = RandomForestClassifier(n_estimators=10,random_state=rState,max_depth=5)\n",
    "#forest.fit(inputy,outputy)\n",
    "forest = forest.fit( train_data[0::,1::], train_data[0::,0] )\n",
    "#predict(inputy)\n",
    "output = forest.predict(test_data).astype(int)\n",
    "summ=0\n",
    "for i in range(int(len(output))):\n",
    "    if output[i]==goodout[i]:\n",
    "        summ+=1\n",
    "accurac=100*float(summ/float(len(output)))\n",
    "print \"Accuracy = \", accurac, \"%\"\n",
    "\n",
    "print 'n_estimators=50:'\n",
    "forest = RandomForestClassifier(n_estimators=50,random_state=rState,max_depth=5)\n",
    "forest = forest.fit( train_data[0::,1::], train_data[0::,0] )\n",
    "output = forest.predict(test_data).astype(int)\n",
    "summ=0\n",
    "for i in range(int(len(output))):\n",
    "    if output[i]==goodout[i]:\n",
    "        summ+=1\n",
    "accurac=100*float(summ/float(len(output)))\n",
    "print \"Accuracy = \", accurac, \"%\"\n",
    "\n",
    "print 'n_estimators=100:'\n",
    "forest = RandomForestClassifier(n_estimators=100,random_state=rState,max_depth=5)\n",
    "forest = forest.fit( train_data[0::,1::], train_data[0::,0] )\n",
    "output = forest.predict(test_data).astype(int)\n",
    "summ=0\n",
    "for i in range(int(len(output))):\n",
    "    if output[i]==goodout[i]:\n",
    "        summ+=1\n",
    "accurac=100*float(summ/float(len(output)))\n",
    "print \"Accuracy = \", accurac, \"%\"\n",
    "\n",
    "print 'n_estimators=200:'\n",
    "forest = RandomForestClassifier(n_estimators=200,random_state=rState,max_depth=5)\n",
    "forest = forest.fit( train_data[0::,1::], train_data[0::,0] )\n",
    "output = forest.predict(test_data).astype(int)\n",
    "summ=0\n",
    "for i in range(int(len(output))):\n",
    "    if output[i]==goodout[i]:\n",
    "        summ+=1\n",
    "accurac=100*float(summ/float(len(output)))\n",
    "print \"Accuracy = \", accurac, \"%\"\n",
    "\n",
    "print 'max_depth=7, instead 5:'\n",
    "forest = RandomForestClassifier(n_estimators=200,random_state=rState,max_depth=7)\n",
    "forest = forest.fit( train_data[0::,1::], train_data[0::,0] )\n",
    "output = forest.predict(test_data).astype(int)\n",
    "summ=0\n",
    "for i in range(int(len(output))):\n",
    "    if output[i]==goodout[i]:\n",
    "        summ+=1\n",
    "accurac=100*float(summ/float(len(output)))\n",
    "print \"Accuracy = \", accurac, \"%\"\n",
    "\n",
    "print 'max_depth=9'\n",
    "forest = RandomForestClassifier(n_estimators=200,random_state=rState,max_depth=9)\n",
    "forest = forest.fit( train_data[0::,1::], train_data[0::,0] )\n",
    "output = forest.predict(test_data).astype(int)\n",
    "summ=0\n",
    "for i in range(int(len(output))):\n",
    "    if output[i]==goodout[i]:\n",
    "        summ+=1\n",
    "accurac=100*float(summ/float(len(output)))\n",
    "print \"Accuracy = \", accurac, \"%\"\n",
    "\n",
    "print 'n_est=200,m_dep=7,bootstrap=False'\n",
    "forest = RandomForestClassifier(n_estimators=200,random_state=rState,max_depth=7,bootstrap=False)\n",
    "forest = forest.fit( train_data[0::,1::], train_data[0::,0] )\n",
    "output = forest.predict(test_data).astype(int)\n",
    "summ=0\n",
    "for i in range(int(len(output))):\n",
    "    if output[i]==goodout[i]:\n",
    "        summ+=1\n",
    "accurac=100*float(summ/float(len(output)))\n",
    "print \"Accuracy = \", accurac, \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier:\n",
      "0.794297352342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "print 'MLP Classifier:'\n",
    "MLP = MLPClassifier(hidden_layer_sizes = (64,16,4) ,\n",
    "                    solver = 'adam',\n",
    "                    activation = 'tanh', \n",
    "                    alpha = 0.01, \n",
    "                    max_iter = 1000,\n",
    "                    batch_size=1,\n",
    "                    learning_rate_init=0.001,\n",
    "                    epsilon=1e-8,\n",
    "                    random_state=2\n",
    "                   )\n",
    "MLP.fit( train_data[0::,1::], train_data[0::,0] )\n",
    "print MLP.score(test_data,goodout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_full_x = train_df.values[0::,1:]\n",
    "train_data_full_y = train_df.values[0::,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772166105499\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(hidden_layer_sizes = (7,3,7) ,\n",
    "                    solver = 'adam',\n",
    "                    activation = 'relu', \n",
    "                    alpha = 0.01, \n",
    "                    max_iter = 100,\n",
    "                    batch_size=20,\n",
    "                    learning_rate_init=0.001,\n",
    "                    epsilon=1e-8\n",
    "                   )\n",
    "MLP.fit( train_data_full_x, train_data_full_y)\n",
    "print MLP.score(train_data_full_x,train_data_full_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81593714927\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(hidden_layer_sizes = (13,11,7,5) ,\n",
    "                    solver = 'adam',\n",
    "                    activation = 'tanh',\n",
    "                    batch_size=1\n",
    "                   )\n",
    "MLP.fit( train_data_full_x, train_data_full_y)\n",
    "print MLP.score(train_data_full_x,train_data_full_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69696969697\n",
      "0.821548821549\n",
      "0.616161616162\n",
      "0.616161616162\n",
      "0.616161616162\n",
      "0.812570145903\n",
      "0.69696969697\n",
      "0.616161616162\n",
      "0.829405162738\n",
      "0.616161616162\n",
      "0.695847362514\n",
      "0.672278338945\n",
      "0.680134680135\n",
      "0.814814814815\n",
      "0.616161616162\n",
      "0.749719416386\n",
      "0.650953984287\n",
      "0.693602693603\n",
      "0.616161616162\n",
      "0.792368125701\n"
     ]
    }
   ],
   "source": [
    "MLP = MLPClassifier(hidden_layer_sizes = (2,4,2,4,2) ,\n",
    "                    solver = 'lbfgs',\n",
    "                    activation = 'tanh',\n",
    "                    batch_size=5,\n",
    "                    max_iter=1000\n",
    "                   )\n",
    "for i in range(20):\n",
    "    MLP.fit( train_data_full_x, train_data_full_y)\n",
    "    print i,\": \",MLP.score(train_data_full_x,train_data_full_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  0.699214365881\n",
      "1 :  0.812570145903\n",
      "2 :  0.753086419753\n",
      "3 :  0.693602693603\n",
      "4 :  0.813692480359\n"
     ]
    }
   ],
   "source": [
    "MLP=MLPClassifier(hidden_layer_sizes=(100, ),\n",
    "                  activation='relu',\n",
    "                  solver='adam',\n",
    "                  alpha=0.0001,\n",
    "                  batch_size='auto',\n",
    "                  learning_rate='constant',\n",
    "                  learning_rate_init=0.001,\n",
    "                  power_t=0.8,\n",
    "                  max_iter=400,\n",
    "                  shuffle=True,\n",
    "                  random_state=None,\n",
    "                  tol=0.0001,\n",
    "                  verbose=False,\n",
    "                  warm_start=False,\n",
    "                  momentum=0.9,\n",
    "                  nesterovs_momentum=True,\n",
    "                  early_stopping=False,\n",
    "                  validation_fraction=0.2,\n",
    "                  beta_1=0.9,\n",
    "                  beta_2=0.999,\n",
    "                  epsilon=1e-8)\n",
    "for i in range(5):\n",
    "    MLP.fit(train_data_full_x,train_data_full_y)\n",
    "    print i,\": \",MLP.score(train_data_full_x,train_data_full_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mega plus scaler potrafi bardzo ulepszyc wyniki\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data_full_x)\n",
    "t_x = scaler.transform(train_data_full_x)\n",
    "t_y=train_data_full_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp after standarization of data:  0.848484848485\n",
      "forest after standarization of data:  0.903479236813\n"
     ]
    }
   ],
   "source": [
    "MLP.fit(t_x,t_y)\n",
    "print 'mlp after standarization of data: ',MLP.score(t_x,t_y)\n",
    "forest.fit(t_x,t_y)\n",
    "print 'forest after standarization of data: ',forest.score(t_x,t_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955106621773\n",
      "891\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes = (75,25), \n",
    "                    solver = 'lbfgs',\n",
    "                    activation = 'tanh', \n",
    "                    alpha = 0.2225, \n",
    "                    max_iter = 1500,\n",
    "                    batch_size=20)\n",
    "clf.fit(t_x,t_y)\n",
    "print clf.score(t_x,t_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445\n",
      "MLP train half:  0.948314606742\n",
      "MLP test half:  0.751121076233\n"
     ]
    }
   ],
   "source": [
    "print len(t_x)/2\n",
    "t_x_1=t_x[:445]\n",
    "t_y_1=t_y[:445]\n",
    "t_x_2=t_x[445:]\n",
    "t_y_2=t_y[445:]\n",
    "clf.fit(t_x_1,t_y[:445])\n",
    "print 'MLP train half: ',clf.score(t_x_1,t_y_1)\n",
    "print 'MLP test half: ',clf.score(t_x_2,t_y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP train half:  0.833707865169\n",
      "MLP test half:  0.811659192825\n"
     ]
    }
   ],
   "source": [
    "testmaxer = MLPClassifier(hidden_layer_sizes = (20,8,16,8,20), \n",
    "                    solver = 'sgd',\n",
    "                    activation = 'tanh', \n",
    "                    alpha = 0.001, \n",
    "                    max_iter = 10000,\n",
    "                    momentum = 0.99,\n",
    "                    batch_size=10)\n",
    "testmaxer.fit(t_x_1,t_y_1)\n",
    "print 'MLP train half: ',testmaxer.score(t_x_1,t_y_1)\n",
    "print 'MLP test half: ',testmaxer.score(t_x_2,t_y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.82737724 -0.56573646  0.43279337 ..., -0.50244517  0.58595414\n",
      "   0.73769513]\n",
      " [-1.56610693  0.66386103  0.43279337 ...,  0.78684529 -1.9423032\n",
      "  -1.35557354]\n",
      " [ 0.82737724 -0.25833709 -0.4745452  ..., -0.48885426  0.58595414\n",
      "  -1.35557354]\n",
      " ..., \n",
      " [ 0.82737724 -0.33518693  0.43279337 ..., -0.49187446  0.58595414\n",
      "   0.73769513]\n",
      " [-0.36936484 -0.1046374  -0.4745452  ..., -0.38667072  0.58595414\n",
      "  -1.35557354]\n",
      " [ 0.82737724 -0.1046374  -0.4745452  ..., -0.485079    0.58595414\n",
      "   0.73769513]]\n"
     ]
    }
   ],
   "source": [
    "print t_x_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
